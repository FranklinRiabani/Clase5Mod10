{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['El', 'perro', 'de', 'San', 'Roque', 'no', 'tiene', 'rabo,', 'porque', 'Ramón', 'Ramírez', 'se', 'lo', 'ha', 'cortado.']\n"
     ]
    }
   ],
   "source": [
    "texto=\"El perro de San Roque no tiene rabo, porque Ramón Ramírez se lo ha cortado.\"\n",
    "tokens=texto.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el',\n",
       " 'perro',\n",
       " 'de',\n",
       " 'san',\n",
       " 'roque',\n",
       " 'no',\n",
       " 'tiene',\n",
       " 'rabo,',\n",
       " 'porque',\n",
       " 'ramón',\n",
       " 'ramírez',\n",
       " 'se',\n",
       " 'lo',\n",
       " 'ha',\n",
       " 'cortado.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2=texto.lower().split()\n",
    "tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'habida', 'teniendo', 'tuviesen', 'estuvo', 'tuvieran', 'fuésemos', 'esta', 'hayas', 'estuvieses', 'eran', 'habremos', 'hubieron', 'he', 'seré', 'habréis', 'un', 'estaríais', 'sois', 'tienen', 'habiendo', 'tenía', 'estuvierais', 'estarían', 'hubieran', 'ante', 'yo', 'tuviera', 'seáis', 'todo', 'hubiésemos', 'tiene', 'hubieseis', 'estuvieras', 'estado', 'tendrás', 'a', 'ese', 'tenido', 'hasta', 'fuimos', 'tuviésemos', 'mis', 'suyas', 'estarías', 'uno', 'porque', 'son', 'estaríamos', 'hayan', 'serías', 'tuvieras', 'estas', 'hubiéramos', 'contra', 'mía', 'ya', 'qué', 'fueses', 'y', 'está', 'estabais', 'seremos', 'habría', 'hubo', 'esas', 'estad', 'otras', 'tuvieron', 'ni', 'habrás', 'durante', 'tuvieses', 'que', 'vuestra', 'estaremos', 'algo', 'estuvimos', 'estar', 'habríais', 'como', 'habéis', 'estuviste', 'una', 'tuvo', 'sí', 'tenías', 'hubiese', 'estabas', 'los', 'este', 'tu', 'míos', 'somos', 'mío', 'pero', 'tendremos', 'te', 'estén', 'estuvieron', 'habrían', 'de', 'sintiendo', 'sería', 'tengáis', 'nosotros', 'tanto', 'hayáis', 'cual', 'fueran', 'habías', 'fuerais', 'estuvieran', 'seréis', 'estoy', 'fuese', 'desde', 'hayamos', 'tendría', 'será', 'ti', 'teníamos', 'vosotras', 'fueras', 'hubiste', 'e', 'con', 'estáis', 'seríais', 'no', 'han', 'seríamos', 'sentid', 'estarán', 'serás', 'tenéis', 'estuviéramos', 'tenemos', 'sentidas', 'estarás', 'vuestras', 'tuviese', 'poco', 'unos', 'habríamos', 'soy', 'ella', 'suyos', 'tengamos', 'estuviera', 'habíais', 'tenga', 'por', 'tendré', 'fuisteis', 'tienes', 'tuve', 'nos', 'hubiera', 'tuvimos', 'del', 'cuando', 'serían', 'estuvieseis', 'estuviese', 'habrías', 'mucho', 'estará', 'tengo', 'hubiesen', 'tú', 'fuera', 'estuviésemos', 'eso', 'donde', 'nuestras', 'haya', 'al', 'sobre', 'tendrán', 'muchos', 'hubisteis', 'fuesen', 'tuyas', 'tuviéramos', 'había', 'estaréis', 'habidas', 'siente', 'tuyos', 'habré', 'nosotras', 'le', 'suyo', 'hemos', 'estando', 'habíamos', 'estéis', 'sea', 'habrán', 'estadas', 'has', 'lo', 'su', 'antes', 'tendréis', 'sentida', 'o', 'nuestra', 'algunas', 'quienes', 'estás', 'también', 'todos', 'os', 'esté', 'esa', 'hubierais', 'mías', 'fuiste', 'tenidos', 'fueseis', 'tuvierais', 'esto', 'las', 'más', 'tengas', 'se', 'nuestros', 'ellos', 'hube', 'estaba', 'estados', 'hay', 'estos', 'tuya', 'habrá', 'habían', 'ellas', 'vosotros', 'tendrían', 'serán', 'ha', 'fue', 'habido', 'fueron', 'tuvisteis', 'estuve', 'el', 'tenidas', 'fui', 'estamos', 'hubieses', 'entre', 'tuvieseis', 'teníais', 'otro', 'fuéramos', 'estaban', 'sus', 'estada', 'seas', 'nada', 'sentido', 'tuyo', 'estuvisteis', 'habidos', 'tengan', 'tenían', 'para', 'sentidos', 'otros', 'sin', 'estaré', 'es', 'tendrías', 'suya', 'mi', 'esos', 'tus', 'tuviste', 'él', 'me', 'otra', 'algunos', 'era', 'estemos', 'estés', 'tendríais', 'tened', 'tenida', 'vuestros', 'sean', 'seamos', 'en', 'tendríamos', 'hubieras', 'erais', 'estaría', 'quien', 'hubimos', 'nuestro', 'vuestro', 'la', 'estábamos', 'les', 'estuviesen', 'mí', 'eras', 'eres', 'muy', 'éramos', 'tendrá', 'están'}\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words(\"spanish\"))\n",
    "#stop_words.add(\"el\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el', 'perro', 'de', 'san', 'roque', 'no', 'tiene', 'rabo', ',', 'porque', 'ramón', 'ramírez', 'se', 'lo', 'ha', 'cortado', '.']\n",
      "['perro', 'san', 'roque', 'rabo', ',', 'ramón', 'ramírez', 'cortado', '.']\n"
     ]
    }
   ],
   "source": [
    "texto=texto.lower()\n",
    "\n",
    "tokens=word_tokenize(texto)\n",
    "print(tokens)\n",
    "\n",
    "texto_filtrado=[word for word in tokens if not word in stop_words]\n",
    "print(texto_filtrado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr\n",
      "corr\n",
      "corr\n",
      "corr\n",
      "camin\n",
      "camin\n",
      "camin\n",
      "camin\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer=SnowballStemmer(\"spanish\")\n",
    "\n",
    "print(stemmer.stem(\"corriendo\"))\n",
    "print(stemmer.stem(\"correr\"))\n",
    "print(stemmer.stem(\"corre\"))\n",
    "print(stemmer.stem(\"corrido\"))\n",
    "print(stemmer.stem(\"caminando\"))\n",
    "print(stemmer.stem(\"caminar\"))\n",
    "print(stemmer.stem(\"camina\"))\n",
    "print(stemmer.stem(\"caminado\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in ./.venv/lib/python3.12/site-packages (from es-core-news-sm==3.7.0) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.3)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./.venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "import es_core_news_sm\n",
    "\n",
    "nlp = es_core_news_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('el', 'DET'), ('perro', 'NOUN'), ('de', 'ADP'), ('san', 'PROPN'), ('roque', 'NOUN'), ('no', 'ADV'), ('tiene', 'VERB'), ('rabo', 'NOUN'), (',', 'PUNCT'), ('porque', 'SCONJ'), ('ramón', 'PROPN'), ('ramírez', 'NOUN'), ('se', 'PRON'), ('lo', 'PRON'), ('ha', 'AUX'), ('cortado', 'VERB'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(texto.lower())\n",
    "print([(w.text,w.pos_) for  w in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corriendo  ->  correr\n",
      "correr  ->  correr\n",
      "corre  ->  correr\n",
      "corrido  ->  corrido\n",
      "caminando  ->  caminar\n",
      "caminar  ->  caminar\n",
      "camina  ->  camina\n",
      "caminado  ->  caminado\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "doc=nlp(\"corriendo correr corre corrido caminando caminar camina caminado\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,' -> ' ,token.lemma_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
